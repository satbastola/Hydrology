{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cec99960-92ba-4cf7-b9b2-c81f39b45b25",
   "metadata": {},
   "source": [
    "# üåä Flood Frequency Analysis Tool ‚Äì Overview & Documentation\n",
    "\n",
    "This tool reads peak flow data from the USGS NWIS database and fits 10 commonly used extreme value probability distributions to estimate flood magnitudes associated with various return periods (e.g., 2-year, 100-year). It performs statistical goodness-of-fit evaluation and provides an interactive interface to visualize the flood frequency curve for each distribution.\n",
    "\n",
    "---\n",
    "\n",
    "## üîß What the Tool Does\n",
    "\n",
    "- ‚úÖ Reads annual peak discharge data from a NWIS `.txt` file\n",
    "- ‚úÖ Fits multiple statistical distributions to the observed peak flows\n",
    "- ‚úÖ Computes estimated flood quantiles for specific return periods (2, 5, 10, 25, 50, 100 years)\n",
    "- ‚úÖ Calculates RMSE and Kolmogorov‚ÄìSmirnov (KS) goodness-of-fit metrics\n",
    "- ‚úÖ Allows the user to interactively select a distribution and view:\n",
    "  - Estimated peak flows\n",
    "  - Distribution parameters\n",
    "  - GOF statistics\n",
    "  - A flood frequency curve plotted in log scale\n",
    "\n",
    "---\n",
    "\n",
    "## üß≠ How to Use\n",
    "\n",
    "1. **Prepare Input File**  \n",
    "   - Download annual peak streamflow data from the [USGS NWIS Peak Flow site](https://waterdata.usgs.gov/nwis/peak)\n",
    "   - Save as a tab-delimited `.txt` file (e.g., `07022500_nwis_peak.txt`)\n",
    "\n",
    "2. **Run the Script in Jupyter Notebook**\n",
    "   - Place the file in your working directory\n",
    "   - Modify the line `usgs_file = \"07022500_nwis_peak.txt\"` to match your filename\n",
    "   - Run the script cell-by-cell\n",
    "\n",
    "3. **Explore Results**\n",
    "   - View the summary table of fitted distribution parameters and their statistical performance\n",
    "   - Use the dropdown selector to compare estimated flood flows and curves for each distribution\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Theoretical Background: Distributions Used\n",
    "\n",
    "Each distribution estimates the probability of rare flood events based on historical data. Here's a quick reference:\n",
    "\n",
    "| Distribution           | Description                                                                 | Parameters                        |\n",
    "|------------------------|-----------------------------------------------------------------------------|-----------------------------------|\n",
    "| **Gumbel (EV1)**        | Models block maxima (e.g., annual max). Skewed right.                      | Location (Œº), Scale (Œ≤)           |\n",
    "| **Log-Pearson III**     | Log-transformed Pearson Type III. Used in U.S. federal flood studies.      | Shape (Œ±), Location (Œº), Scale    |\n",
    "| **GEV**                 | General form for extremes. Includes Gumbel, Frechet, Weibull as cases.     | Shape (Œæ), Location, Scale        |\n",
    "| **Normal**              | Symmetric bell curve. May misrepresent skewed flood data.                  | Mean (Œº), Std. dev. (œÉ)           |\n",
    "| **Lognormal**           | Data is normally distributed after log transform. Skewed right.            | Shape (œÉ), Location, Scale        |\n",
    "| **Weibull (Type III)**  | Useful for extreme minimums or upper tails.                                | Shape (k), Location, Scale        |\n",
    "| **Exponential**         | Special case of Weibull; constant failure rate (rarely used for floods).   | Rate (Œª) or Scale                 |\n",
    "| **Gamma**               | General skewed distribution, flexible fit for hydrology                    | Shape (k), Scale (Œ∏), Location    |\n",
    "| **Loglogistic (Fisk)**  | Skewed right, like lognormal but heavier tail.                             | Shape (c), Location, Scale        |\n",
    "| **Generalized Pareto**  | Models excesses over a threshold (POT approach).                           | Shape, Location, Scale            |\n",
    "\n",
    "---\n",
    "\n",
    "## üìè Performance Evaluation Criteria\n",
    "\n",
    "Two statistical metrics assess how well each distribution fits the observed data:\n",
    "\n",
    "- ### üîπ Root Mean Squared Error (RMSE)\n",
    "  Measures average error between observed peak flows and estimated quantiles from the distribution:\n",
    "  $$\n",
    "  \\text{RMSE} = \\sqrt{ \\frac{1}{n} \\sum (Q_{\\text{obs}} - Q_{\\text{est}})^2 }\n",
    "  $$\n",
    "  Lower values indicate a better fit.\n",
    "\n",
    "- ### üîπ Kolmogorov‚ÄìSmirnov (KS) Statistic\n",
    "  Measures the maximum difference between the empirical cumulative distribution function (ECDF) and the theoretical CDF:\n",
    "  $$\n",
    "  D = \\sup_x |F_n(x) - F(x)|\n",
    "  $$\n",
    "  - Returns both the **KS statistic** and a **p-value**\n",
    "  - If p-value > 0.05: distribution is a statistically valid fit (‚úÖ Pass)\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Output Summary\n",
    "\n",
    "- A sorted summary table of all distributions including:\n",
    "  - Fitted parameters\n",
    "  - RMSE\n",
    "  - KS statistic and p-value\n",
    "  - Pass/fail interpretation\n",
    "- Interactive flood frequency plots for return periods on a log-x axis\n",
    "- Ability to choose which distribution best represents the dataset\n",
    "\n",
    "---\n",
    "\n",
    "## üí° Applications\n",
    "\n",
    "- Floodplain mapping\n",
    "- Hydraulic structure design (culverts, bridges, dams)\n",
    "- Return period‚Äìbased risk estimation\n",
    "- Hydrologic modeling calibration\n",
    "\n",
    "---\n",
    "\n",
    "Let me know if you'd like this tool extended with confidence intervals, percentile shading, or exported reports in Excel or PDF!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7643db02-d399-40cf-99b6-696997476e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    site_no    peak_dt  peak_va\n",
      "2  07022500 1953-03-03    780.0\n",
      "3  07022500 1954-01-20    520.0\n",
      "4  07022500 1955-03-20    846.0\n",
      "5  07022500 1956-02-02    440.0\n",
      "6  07022500 1957-01-22    707.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\satis\\AppData\\Local\\Temp\\ipykernel_108552\\3695952954.py:37: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['peak_dt'] = pd.to_datetime(df['peak_dt'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gumbel_r\n",
    "from ipywidgets import interact, Dropdown\n",
    "def read_nwis_peak_file(file_path):\n",
    "    \"\"\"\n",
    "    Reads a USGS NWIS peak flow .txt file and extracts peak flow data.\n",
    "    Handles comment lines and parses peak date and discharge values.\n",
    "    \n",
    "    Parameters:\n",
    "        file_path (str): Path to NWIS peak flow text file\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with columns ['site_no', 'peak_dt', 'peak_va'] (site, date, peak flow)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        # Identify the header (first non-commented line)\n",
    "        start_line = next(i for i, line in enumerate(lines) if not line.startswith('#'))\n",
    "\n",
    "        # Read data starting at detected header\n",
    "        df = pd.read_csv(\n",
    "            file_path,\n",
    "            sep='\\t',\n",
    "            comment='#',\n",
    "            header=0,\n",
    "            dtype=str,\n",
    "            engine='python'\n",
    "        )\n",
    "\n",
    "        # Clean and convert key columns\n",
    "        df.columns = df.columns.str.strip()\n",
    "        df['peak_dt'] = pd.to_datetime(df['peak_dt'], errors='coerce')\n",
    "        df['peak_va'] = pd.to_numeric(df['peak_va'], errors='coerce')\n",
    "\n",
    "        # Drop rows with invalid data\n",
    "        df_clean = df[['site_no', 'peak_dt', 'peak_va']].dropna()\n",
    "\n",
    "        return df_clean\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error reading file: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# üîç Example usage\n",
    "# --- Step 1: Load USGS Peak Flow Data (Annual Max Series) ---\n",
    "# Replace this with the path to your downloaded USGS data (CSV or TXT)\n",
    "\n",
    "usgs_file = \"07022500_nwis_peak.txt\"\n",
    "peak_df = read_nwis_peak_file(usgs_file)\n",
    "\n",
    "# üìä Preview the data\n",
    "print(peak_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c47ac05-66f3-4001-9f83-66350098ecbf",
   "metadata": {},
   "source": [
    "# üìò Self-Assessment: Flood Frequency Analysis Tool\n",
    "\n",
    "Use these prompts and questions to evaluate your understanding of the tool and its underlying hydrologic and statistical concepts.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Conceptual Questions\n",
    "\n",
    "1. **Why are return periods plotted on a logarithmic scale in flood frequency analysis?**\n",
    "   - *Hint: Think about how frequent vs. rare events are distributed.*\n",
    "\n",
    "2. **What is the purpose of fitting multiple distributions to the same peak flow dataset?**\n",
    "   - *Hint: No single distribution fits all scenarios equally well.*\n",
    "\n",
    "3. **How do Gringorten plotting positions help in flood frequency analysis?**\n",
    "   - *Hint: They're used to assign empirical probabilities to ordered data.*\n",
    "\n",
    "4. **What assumptions underlie the use of the Gumbel distribution in hydrology?**\n",
    "   - *Hint: It‚Äôs designed to model block maxima like annual peak flows.*\n",
    "\n",
    "5. **How do parametric and non-parametric flood frequency methods differ in their approach?**\n",
    "   - *Hint: Consider how the data distribution is treated.*\n",
    "\n",
    "---\n",
    "\n",
    "## üîç Reflective Prompts\n",
    "\n",
    "1. **If two distributions yield similar RMSE but different KS p-values, which metric is more important for selecting a model‚Äîand why?**\n",
    "\n",
    "2. **Can a statistically good-fitting distribution be inappropriate for design applications? Provide an example.**\n",
    "\n",
    "3. **How would you adapt this tool to process data from multiple gage stations simultaneously?**\n",
    "\n",
    "4. **What limitations might this tool face when applied to future climate-affected streamflow patterns?**\n",
    "\n",
    "5. **How would the analysis change if you used partial-duration series instead of annual maxima?**\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Quiz Questions\n",
    "\n",
    "**Q1.** The Gumbel distribution is commonly used to model:  \n",
    "A. Rainfall intensity  \n",
    "B. Annual maximum values  \n",
    "C. Median flow durations  \n",
    "D. Baseflow during drought  \n",
    "‚úÖ **Correct:** B\n",
    "\n",
    "---\n",
    "\n",
    "**Q2.** The Kolmogorov‚ÄìSmirnov test compares:  \n",
    "A. Log and normal distributions  \n",
    "B. ECDF and theoretical CDF  \n",
    "C. Mean annual rainfall  \n",
    "D. Number of peaks above threshold  \n",
    "‚úÖ **Correct:** B\n",
    "\n",
    "---\n",
    "\n",
    "**Q3.** In the Generalized Extreme Value distribution, the shape parameter controls:  \n",
    "A. Peak discharge  \n",
    "B. Tail behavior  \n",
    "C. Cumulative runoff  \n",
    "D. Frequency of low flows  \n",
    "‚úÖ **Correct:** B\n",
    "\n",
    "---\n",
    "\n",
    "**Q4.** A high KS p-value and low RMSE suggest:  \n",
    "A. Overfitting  \n",
    "B. Good model fit  \n",
    "C. Poor data resolution  \n",
    "D. Statistical bias  \n",
    "‚úÖ **Correct:** B\n",
    "\n",
    "---\n",
    "\n",
    "**Q5.** Which distribution is least appropriate for positively skewed hydrologic data?  \n",
    "A. Gumbel  \n",
    "B. Lognormal  \n",
    "C. Normal  \n",
    "D. Log-Pearson III  \n",
    "‚úÖ **Correct:** C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d100d89-68e3-4c92-9cb3-a8f04eec3a5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
